X_train: (60000, 784)
X_test:  (10000, 784)
X_train: (60000, 784)
X_test:  (10000, 784)
Learning rate: 0.04
Batch size: 4, Epochs: 8.
Loss: 2.4171442226369297, Learning time: 1319.9680.
Learning rate: 0.04
Batch size: 4, Epochs: 8.
Loss: 2.4091447008943567, Learning time: 1469.4391.
Test size: 1000
Accuracy: 9.9750%, Average entropy: 2.26685455682486
Learning rate: 0.04
Batch size: 6000, Epochs: 8.
Loss: 2.301234470351758, Learning time: 2096.5923.
Test size: 10000
Accuracy: 11.2367%, Average entropy: 2.301409266441671
Learning rate: 0.8
Batch size: 6000, Epochs: 8.
Loss: 2.302077304401535, Learning time: 2262.4016.
Test size: 10000
Accuracy: 10.4417%, Average entropy: 2.3004260371912824
Learning rate: 0.08
Batch size: 600, Epochs: 4.
Loss: 2.301432670742864, Learning time: 898.6059.
Test size: 10000
Accuracy: 10.4417%, Average entropy: 2.301329288927323
Learning rate: 0.008
Batch size: 64, Epochs: 4.
Loss: 2.3016951341946648, Learning time: 786.7803.
Test size: 10000
Accuracy: 10.4417%, Average entropy: 2.301369915249154
Learning rate: 0.0006
Batch size: 64, Epochs: 20.
Loss: 2.3011940715056465, Learning time: 19186.1236.
Test size: 10000
Accuracy: 11.2367%, Average entropy: 2.3012324106662274
Learning rate: 0.0004
Batch size: 32, Epochs: 4.
Loss: 2.294700806509116, Learning time: 823.2540.
Test size: 10000
Accuracy: 13.0933%, Average entropy: 2.3016190354144834
Architecture: [(1, 3), (1, 16), (1, 32), (1, 64), (1, 128)]
Learning rate: 0.001
Batch size: 32, Epochs: 2.
Loss: 2.3078017915688545, Learning time: 449.8374.
Test size: 10000
Accuracy: 12.5150%, Average entropy: 2.301664779518237
Architecture: [(1, 3), (1, 16), (1, 32), (1, 64), (1, 128)]
Learning rate: 0.015
Batch size: 32, Epochs: 2.
Loss: 2.133983214684785, Learning time: 316.6182.
Test size: 10000
Accuracy: 28.2000%, Average entropy: 2.2570147968449024
Architecture: [(1, 3), (1, 16), (1, 32), (1, 64), (1, 128)]
Learning rate: 0.0125
Batch size: 32, Epochs: 5.
Loss: 2.0132102281983, Learning time: 791.1637.
Architecture: [(1, 3), (1, 16), (1, 32), (1, 64), (1, 128)]
Learning rate: 0.009825
Batch size: 32, Epochs: 5.
Loss: 1.631411516144861, Learning time: 798.9097.
Architecture: [(1, 3), (1, 16), (1, 32), (1, 64), (1, 128)]
Learning rate: 0.01
Batch size: 128, Epochs: 5.
Loss: 2.241234299443902, Learning time: 461.0866.
